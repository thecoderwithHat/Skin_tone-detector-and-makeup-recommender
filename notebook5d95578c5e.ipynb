{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11122792,"sourceType":"datasetVersion","datasetId":6936151}],"dockerImageVersionId":30920,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/vaibsdev/notebook5d95578c5e?scriptVersionId=234270935\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"","metadata":{"id":"mogcXLh2bfGp","outputId":"de631786-5f70-4abf-ec90-6208519041f9","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom PIL import Image\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport json\nimport pickle\nimport warnings\nimport pandas as pd\n!pip install torchinfo\nfrom torchinfo import summary\nimport gc\n\nwarnings.filterwarnings('ignore')","metadata":{"id":"u240nsgdZV4d","outputId":"eecb1437-0d1c-4771-b087-af7e31f4191d","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\nprint(f\"CUDA Available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"CUDA Device Count: {torch.cuda.device_count()}\")\n    print(f\"CUDA Device Name: {torch.cuda.get_device_name(0)}\")\n\n\ndef move_to_device(obj, device):\n    if isinstance(obj, torch.nn.Module):\n        return obj.to(device)\n    elif isinstance(obj, torch.Tensor):\n        return obj.to(device)\n    return obj\n\n\nsample_tensor = torch.tensor([1.0]).to(device)\nprint(f\"Tensor on {sample_tensor.device}\")\n","metadata":{"id":"NshyeSyfZaA7","outputId":"90d5fc33-3d70-4cde-c451-6c2ba829d42d","trusted":true,"execution":{"iopub.status.busy":"2025-04-14T19:40:02.320225Z","iopub.execute_input":"2025-04-14T19:40:02.320534Z","iopub.status.idle":"2025-04-14T19:40:02.328307Z","shell.execute_reply.started":"2025-04-14T19:40:02.32051Z","shell.execute_reply":"2025-04-14T19:40:02.327594Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nCUDA Available: True\nCUDA Device Count: 1\nCUDA Device Name: Tesla P100-PCIE-16GB\nTensor on cuda:0\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"\nclass EarlyStopping:\n    \"\"\"Early stopping handler to prevent overfitting\"\"\"\n    def __init__(self, patience=5, min_delta=0.001, save_path=\"best_model.pth\"):\n        self.patience = patience\n        self.min_delta = min_delta\n        self.save_path = save_path\n        self.best_loss = float('inf')\n        self.counter = 0\n\n    def __call__(self, val_loss, model):\n        if val_loss < self.best_loss - self.min_delta:\n            self.best_loss = val_loss\n            self.counter = 0\n            # Save the best model\n            torch.save(model.state_dict(), self.save_path)\n            print(f\"[INFO] Model checkpoint saved to {self.save_path}\")\n            return False\n        else:\n            self.counter += 1\n            if self.counter >= self.patience:\n                print(\"[INFO] Early stopping triggered.\")\n                return True\n        return False","metadata":{"id":"a1e8s7-eeV3F","trusted":true,"execution":{"iopub.status.busy":"2025-04-14T19:40:04.66474Z","iopub.execute_input":"2025-04-14T19:40:04.665032Z","iopub.status.idle":"2025-04-14T19:40:04.670686Z","shell.execute_reply.started":"2025-04-14T19:40:04.665011Z","shell.execute_reply":"2025-04-14T19:40:04.669807Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"\ncsv_path = '/kaggle/input/mst-e-data-1/mst-e_data/mst-e_image_details.csv'\nimage_data = pd.read_csv(csv_path)\n\n\nimage_paths = []\nlabels = []\n\n\nbase_image_dir = \"/kaggle/input/mst-e-data-1/mst-e_data\"\n\n\nunique_mst_classes = sorted(image_data['MST'].unique())\nclass_to_idx = {class_name: idx for idx, class_name in enumerate(unique_mst_classes)}\nnum_classes = len(unique_mst_classes)\nprint(f\"Number of unique MST classes: {num_classes}\")\nprint(f\"Class mapping: {class_to_idx}\")\n\n\nfor index, row in image_data.iterrows():\n    # Get image details from your columns\n    image_id = row['image_ID']\n    subject_name = row['subject_name']\n\n \n    mst_class = row['MST']\n    class_idx = class_to_idx[mst_class]\n\n    image_path = os.path.join(base_image_dir, subject_name, f\"{image_id}\")\n\n    # Skip if this is an MP4 file\n    if image_path.lower().endswith('.mp4'):\n        continue\n\n    \n    if os.path.exists(image_path):\n        image_paths.append(image_path)\n        labels.append(class_idx)  \n    else:\n        print(f\"Image not found: {image_path}\")\n\nprint(f\"Found {len(image_paths)} images across {num_classes} MST classes\")","metadata":{"id":"V_UdV5bWZfPL","outputId":"43608adc-142a-4277-bd62-6b565666b85e","trusted":true,"execution":{"iopub.status.busy":"2025-04-14T19:40:06.779209Z","iopub.execute_input":"2025-04-14T19:40:06.779538Z","iopub.status.idle":"2025-04-14T19:40:08.904075Z","shell.execute_reply.started":"2025-04-14T19:40:06.779509Z","shell.execute_reply":"2025-04-14T19:40:08.9033Z"}},"outputs":[{"name":"stdout","text":"Number of unique MST classes: 10\nClass mapping: {1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7, 9: 8, 10: 9}\nImage not found: /kaggle/input/mst-e-data-1/mst-e_data/subject_18/PXL_20220922_183142438.jpg \nImage not found: /kaggle/input/mst-e-data-1/mst-e_data/subject_2/bottom\nFound 1510 images across 10 MST classes\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"class SkinToneDataset(Dataset):\n    \"\"\"Custom Dataset for loading skin tone images\"\"\"\n    def __init__(self, image_paths, labels, transform=None):\n        self.image_paths = image_paths\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        label = self.labels[idx]\n\n        img = Image.open(img_path).convert(\"RGB\")\n        if self.transform:\n            img = self.transform(img)\n\n        return img, torch.tensor(label, dtype=torch.long)","metadata":{"id":"f1rPtJMictLg","trusted":true,"execution":{"iopub.status.busy":"2025-04-14T19:40:09.614097Z","iopub.execute_input":"2025-04-14T19:40:09.614424Z","iopub.status.idle":"2025-04-14T19:40:09.619705Z","shell.execute_reply.started":"2025-04-14T19:40:09.614397Z","shell.execute_reply":"2025-04-14T19:40:09.618878Z"}},"outputs":[],"execution_count":37},{"cell_type":"markdown","source":"RESNet\n","metadata":{}},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T19:40:12.025129Z","iopub.execute_input":"2025-04-14T19:40:12.02542Z","iopub.status.idle":"2025-04-14T19:40:12.03054Z","shell.execute_reply.started":"2025-04-14T19:40:12.0254Z","shell.execute_reply":"2025-04-14T19:40:12.029576Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"train_paths, val_paths, train_labels, val_labels = train_test_split(\n    image_paths, labels, test_size=0.2, stratify=labels, random_state=42\n)\ntrain_dataset = SkinToneDataset(train_paths, train_labels, transform=transform)\nval_dataset = SkinToneDataset(val_paths, val_labels, transform=transform)\n\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T19:40:28.601139Z","iopub.execute_input":"2025-04-14T19:40:28.601429Z","iopub.status.idle":"2025-04-14T19:40:28.609832Z","shell.execute_reply.started":"2025-04-14T19:40:28.601408Z","shell.execute_reply":"2025-04-14T19:40:28.609031Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"import torchvision.models as models\n\nclass SkinToneResNet(nn.Module):\n    \"\"\"ResNet-based model for skin tone classification.\"\"\"\n    def __init__(self, num_classes):\n        super(SkinToneResNet, self).__init__()\n        \n        # Load a pre-trained ResNet model\n        self.resnet = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n        \n        # Freeze feature extraction layers for transfer learning\n        for param in self.resnet.parameters():\n            param.requires_grad = False  \n\n        # Modify the fully connected layer for our task\n        in_features = self.resnet.fc.in_features\n        self.resnet.fc = nn.Sequential(\n            nn.Linear(in_features, 256),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(256, num_classes)\n        )\n\n    def forward(self, x):\n        return self.resnet(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T19:34:08.13344Z","iopub.execute_input":"2025-04-14T19:34:08.133732Z","iopub.status.idle":"2025-04-14T19:34:08.139138Z","shell.execute_reply.started":"2025-04-14T19:34:08.133703Z","shell.execute_reply":"2025-04-14T19:34:08.138192Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = SkinToneResNet(num_classes=num_classes).to(device)\n\ncriterion = nn.CrossEntropyLoss()  # Loss function\noptimizer = optim.Adam(model.resnet.fc.parameters(), lr=0.0005, weight_decay=1e-4)  # L2 regularization\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T19:34:11.254817Z","iopub.execute_input":"2025-04-14T19:34:11.255126Z","iopub.status.idle":"2025-04-14T19:34:11.513698Z","shell.execute_reply.started":"2025-04-14T19:34:11.255105Z","shell.execute_reply":"2025-04-14T19:34:11.513017Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"num_epochs = 15  # Adjust as needed\nearly_stopping = EarlyStopping(patience=5, min_delta=0.001, save_path=\"best_model.pth\")\n\ntrain_losses = []\ntrain_accuracies = []\nval_losses = []\nval_accuracies = []\n\nfor epoch in range(num_epochs):\n    model.train()\n    total_loss, correct, total = 0, 0, 0\n\n    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n        images, labels = images.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n        _, predicted = torch.max(outputs, 1)\n        correct += (predicted == labels).sum().item()\n        total += labels.size(0)\n\n    train_acc = correct / total\n    train_loss = total_loss / len(train_loader)\n\n    train_losses.append(train_loss)\n    train_accuracies.append(train_acc)\n\n    scheduler.step()  # Adjust learning rate\n\n    print(f\"[Epoch {epoch+1}] Train Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}\")\n\n    model.eval()\n    val_loss, val_correct, val_total = 0, 0, 0\n\n    with torch.no_grad():\n        for images, labels in val_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n\n            val_loss += loss.item()\n            _, predicted = torch.max(outputs, 1)\n            val_correct += (predicted == labels).sum().item()\n            val_total += labels.size(0)\n\n    val_acc = val_correct / val_total\n    val_loss = val_loss / len(val_loader)\n\n    val_losses.append(val_loss)\n    val_accuracies.append(val_acc)\n\n    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}\")\n\n    # Early Stopping Check\n    if early_stopping(val_loss, model):\n        break \n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T19:34:17.076614Z","iopub.execute_input":"2025-04-14T19:34:17.076935Z","iopub.status.idle":"2025-04-14T19:36:11.618253Z","shell.execute_reply.started":"2025-04-14T19:34:17.076913Z","shell.execute_reply":"2025-04-14T19:36:11.61731Z"}},"outputs":[{"name":"stderr","text":"Epoch 1/1: 100%|██████████| 38/38 [01:28<00:00,  2.34s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 1] Train Loss: 1.8976, Accuracy: 0.3651\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Validation Loss: 1.3283, Validation Accuracy: 0.7914\n[INFO] Model checkpoint saved to best_model.pth\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"# Plot Losses\nepochs_range = range(1, len(train_losses) + 1)\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, train_losses, label='Train Loss')\nplt.plot(epochs_range, val_losses, label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Loss over Epochs')\nplt.legend(loc='upper right')\n\n# Plot Accuracies\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, train_accuracies, label='Train Accuracy')\nplt.plot(epochs_range, val_accuracies, label='Validation Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.title('Accuracy over Epochs')\nplt.legend(loc='lower right')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T19:36:11.619564Z","iopub.execute_input":"2025-04-14T19:36:11.619819Z","iopub.status.idle":"2025-04-14T19:36:11.993062Z","shell.execute_reply.started":"2025-04-14T19:36:11.619798Z","shell.execute_reply":"2025-04-14T19:36:11.992163Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 2 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"# After training completes, to clear GPU memory:\nmodel = model.to('cpu')  # Move model back to CPU\ntorch.cuda.empty_cache()  # Clear CUDA cache\ngc.collect()  # Trigger garbage collection\n\n# # If you're working in a notebook, you might want to manually delete variables\n# del model, train_loader, val_loader, images, labels, outputs, loss, optimizer, scheduler\n# gc.collect()  # Run garbage collection again\n# torch.cuda.empty_cache()  # Empty cache once more","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T19:36:18.012672Z","iopub.execute_input":"2025-04-14T19:36:18.012968Z","iopub.status.idle":"2025-04-14T19:36:18.243714Z","shell.execute_reply.started":"2025-04-14T19:36:18.012948Z","shell.execute_reply":"2025-04-14T19:36:18.242995Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"7111"},"metadata":{}}],"execution_count":29},{"cell_type":"markdown","source":"-------------------------------------------------------------------------------","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class SkinToneModel(nn.Module):\n    \"\"\"Convolutional Neural Network for skin tone classification\"\"\"\n    def __init__(self, num_classes, dropout_rate=0.3):\n        super(SkinToneModel, self).__init__()\n        \n        self.conv_block1 = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=3, padding=\"same\"),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2),\n        )\n        \n        self.conv_block2 = nn.Sequential(\n            nn.Conv2d(64, 128, kernel_size=3, padding=\"same\"),\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2),\n        )\n        \n        self.conv_block3 = nn.Sequential(\n            nn.Conv2d(128, 256, kernel_size=3, padding=\"same\"),\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2),\n            nn.Dropout2d(p=0.2)\n        )\n        \n        self.conv_block4 = nn.Sequential(\n            nn.Conv2d(256, 256, kernel_size=3, padding=\"same\"),\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2),\n            # nn.Dropout2d(p=0.3)\n        )\n        \n        # Corrected input channels from 512 to 256\n        self.conv_block5 = nn.Sequential(\n            nn.Conv2d(256, 512, kernel_size=3, padding=\"same\"),  # in_channels=256\n            nn.BatchNorm2d(512),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2)\n        )\n        \n        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n        \n        self.fc_block = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(512, 256),\n            nn.ReLU(),\n            nn.Dropout(dropout_rate),\n            nn.Linear(256, num_classes)  # Corrected from 512 to 256\n        )\n\n    def forward(self, x):\n        x = self.conv_block1(x)\n        x = self.conv_block2(x)\n        x = self.conv_block3(x)\n        x = self.conv_block4(x)\n        x = self.conv_block5(x)\n        x = self.global_avg_pool(x)\n        x = self.fc_block(x)\n        return x\n\n\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n\ndataset = SkinToneDataset(image_paths, labels, transform=transform)\n\n# Split dataset into training and validation sets (80% train, 20% validation)\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\ntrain_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4,persistent_workers=True,pin_memory = True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4,persistent_workers=True,pin_memory = True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else print(\"ERROR\"))\nmodel = SkinToneModel(num_classes=num_classes).to(device)\n\n\nprint(\"Basic Model:\")\nprint(summary(model, input_size=(1, 3, 224, 224)))\n# print(\"\\nLighting-Aware Model:\")\n# print(summary(lighting_model, input_size=(1, 3, 224, 224)))\n\n\ncriterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n    \n    \noptimizer = torch.optim.Adam(model.parameters(), lr=0.0003) #changed \n","metadata":{"id":"FWmPgWvPd8a3","outputId":"0328f1d6-8a3a-4be3-d045-86f5dbed559d","trusted":true,"execution":{"iopub.status.busy":"2025-04-14T19:41:54.565704Z","iopub.execute_input":"2025-04-14T19:41:54.566015Z","iopub.status.idle":"2025-04-14T19:41:54.62202Z","shell.execute_reply.started":"2025-04-14T19:41:54.56598Z","shell.execute_reply":"2025-04-14T19:41:54.621056Z"}},"outputs":[{"name":"stdout","text":"Basic Model:\n==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nSkinToneModel                            [1, 10]                   --\n├─Sequential: 1-1                        [1, 64, 112, 112]         --\n│    └─Conv2d: 2-1                       [1, 64, 224, 224]         1,792\n│    └─BatchNorm2d: 2-2                  [1, 64, 224, 224]         128\n│    └─ReLU: 2-3                         [1, 64, 224, 224]         --\n│    └─MaxPool2d: 2-4                    [1, 64, 112, 112]         --\n├─Sequential: 1-2                        [1, 128, 56, 56]          --\n│    └─Conv2d: 2-5                       [1, 128, 112, 112]        73,856\n│    └─BatchNorm2d: 2-6                  [1, 128, 112, 112]        256\n│    └─ReLU: 2-7                         [1, 128, 112, 112]        --\n│    └─MaxPool2d: 2-8                    [1, 128, 56, 56]          --\n├─Sequential: 1-3                        [1, 256, 28, 28]          --\n│    └─Conv2d: 2-9                       [1, 256, 56, 56]          295,168\n│    └─BatchNorm2d: 2-10                 [1, 256, 56, 56]          512\n│    └─ReLU: 2-11                        [1, 256, 56, 56]          --\n│    └─MaxPool2d: 2-12                   [1, 256, 28, 28]          --\n│    └─Dropout2d: 2-13                   [1, 256, 28, 28]          --\n├─Sequential: 1-4                        [1, 256, 14, 14]          --\n│    └─Conv2d: 2-14                      [1, 256, 28, 28]          590,080\n│    └─BatchNorm2d: 2-15                 [1, 256, 28, 28]          512\n│    └─ReLU: 2-16                        [1, 256, 28, 28]          --\n│    └─MaxPool2d: 2-17                   [1, 256, 14, 14]          --\n├─Sequential: 1-5                        [1, 512, 7, 7]            --\n│    └─Conv2d: 2-18                      [1, 512, 14, 14]          1,180,160\n│    └─BatchNorm2d: 2-19                 [1, 512, 14, 14]          1,024\n│    └─ReLU: 2-20                        [1, 512, 14, 14]          --\n│    └─MaxPool2d: 2-21                   [1, 512, 7, 7]            --\n├─AdaptiveAvgPool2d: 1-6                 [1, 512, 1, 1]            --\n├─Sequential: 1-7                        [1, 10]                   --\n│    └─Flatten: 2-22                     [1, 512]                  --\n│    └─Linear: 2-23                      [1, 256]                  131,328\n│    └─ReLU: 2-24                        [1, 256]                  --\n│    └─Dropout: 2-25                     [1, 256]                  --\n│    └─Linear: 2-26                      [1, 10]                   2,570\n==========================================================================================\nTotal params: 2,277,386\nTrainable params: 2,277,386\nNon-trainable params: 0\nTotal mult-adds (G): 2.64\n==========================================================================================\nInput size (MB): 0.60\nForward/backward pass size (MB): 94.73\nParams size (MB): 9.11\nEstimated Total Size (MB): 104.45\n==========================================================================================\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"#FOR NORMAL MODEL\ndef train_one_epoch(model, dataloader, criterion, optimizer, device):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    for inputs, labels in dataloader:\n        inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)  # Move to GPU\n\n        optimizer.zero_grad()  \n\n        outputs = model(inputs)  \n        loss = criterion(outputs, labels)\n\n        loss.backward()  \n        optimizer.step() \n\n        running_loss += loss.item() * inputs.size(0)\n        _, predicted = outputs.max(1)\n        total += labels.size(0)\n        correct += predicted.eq(labels).sum().item()\n\n    epoch_loss = running_loss / len(dataloader.dataset)\n    epoch_acc = 100.0 * correct / total\n\n    return epoch_loss, epoch_acc\n\ndef validate(model, dataloader, criterion, device):\n    model.eval()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for inputs, labels in dataloader:\n            inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n\n            outputs = model(inputs)  # Forward pass\n            loss = criterion(outputs, labels)\n            running_loss += loss.item() * inputs.size(0)\n            _, predicted = outputs.max(1)\n            total += labels.size(0)\n            correct += predicted.eq(labels).sum().item()\n\n    epoch_loss = running_loss / len(dataloader.dataset)\n    epoch_acc = 100.0 * correct / total\n    print(epoch_loss)\n    print(epoch_acc)\n\n    return epoch_loss, epoch_acc\n\n\n# Ensure model is on GPU\nmodel.to(device)\n\n\nearly_stopping = EarlyStopping(patience=5, min_delta=0.001, save_path=\"best_skin_tone_model.pth\")\n\ntrain_losses = []\nval_losses = []\ntrain_accuracies = []\nval_accuracies = []\nnum_epochs = 50\nfor epoch in range(num_epochs):\n    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n    val_loss, val_acc = validate(model, val_loader, criterion, device)\n\n     # Save loss and accuracy for visualization\n    train_losses.append(train_loss)\n    val_losses.append(val_loss)\n    train_accuracies.append(train_acc)\n    val_accuracies.append(val_acc)\n\n\n    print(f'Epoch {epoch+1}/{num_epochs}: '\n          f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, '\n          f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n\n    if early_stopping(val_loss, model):\n        print(f\"Training stopped early at epoch {epoch+1}\")\n        break\n\nprint(f'Training complete! Best validation loss: {early_stopping.best_loss:.4f}')\n\n# Load the best model for evaluation\nmodel.load_state_dict(torch.load(early_stopping.save_path, map_location=device))\nfinal_val_loss, final_val_acc = validate(model, val_loader, criterion, device)\nprint(f'Final model performance - Validation Loss: {final_val_loss:.4f}, Validation Accuracy: {final_val_acc:.2f}%')","metadata":{"id":"zS7vEOQcoT1L","outputId":"0b805ac4-432e-4604-8a2a-9d34e5c92802","trusted":true,"execution":{"iopub.status.busy":"2025-04-14T19:36:30.219545Z","iopub.execute_input":"2025-04-14T19:36:30.219836Z","iopub.status.idle":"2025-04-14T19:36:30.374395Z","shell.execute_reply.started":"2025-04-14T19:36:30.219816Z","shell.execute_reply":"2025-04-14T19:36:30.372742Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-fa4377d6111d>\u001b[0m in \u001b[0;36m<cell line: 65>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-31-fa4377d6111d>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, dataloader, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Move to GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1463\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1464\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1465\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1467\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1489\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1490\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1491\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1492\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    713\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 715\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/worker.py\", line 351, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 50, in fetch\n    data = self.dataset.__getitems__(possibly_batched_index)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\", line 420, in __getitems__\n    return [self.dataset[self.indices[idx]] for idx in indices]\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\", line 420, in <listcomp>\n    return [self.dataset[self.indices[idx]] for idx in indices]\n  File \"<ipython-input-22-953e8f679307>\", line 13, in __getitem__\n    label = self.labels[idx]\nRuntimeError: CUDA error: initialization error\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\n"],"ename":"RuntimeError","evalue":"Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/worker.py\", line 351, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 50, in fetch\n    data = self.dataset.__getitems__(possibly_batched_index)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\", line 420, in __getitems__\n    return [self.dataset[self.indices[idx]] for idx in indices]\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\", line 420, in <listcomp>\n    return [self.dataset[self.indices[idx]] for idx in indices]\n  File \"<ipython-input-22-953e8f679307>\", line 13, in __getitem__\n    label = self.labels[idx]\nRuntimeError: CUDA error: initialization error\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\n","output_type":"error"}],"execution_count":31},{"cell_type":"code","source":"\nclass SkinToneDataset(Dataset):\n    \"\"\"Custom Dataset for loading skin tone images\"\"\"\n    def __init__(self, image_paths, labels, transform=None):\n        self.image_paths = image_paths\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        label = self.labels[idx]\n\n        img = Image.open(img_path).convert(\"RGB\")\n        if self.transform:\n            img = self.transform(img)\n\n        return img, torch.tensor(label, dtype=torch.long)\nclass LightingAwareAttention(nn.Module):\n    \"\"\"Attention mechanism to focus on lighting-invariant features\"\"\"\n    def __init__(self, in_channels):\n        super(LightingAwareAttention, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, in_channels // 8, kernel_size=1)\n        self.conv2 = nn.Conv2d(in_channels // 8, in_channels, kernel_size=1)\n        self.sigmoid = nn.Sigmoid()\n        \n    def forward(self, x):\n        # Global average pooling to capture lighting information\n        avg_pool = torch.mean(x, dim=[2, 3], keepdim=True)\n        \n        # Apply attention calculation\n        y = self.conv1(avg_pool)\n        y = nn.ReLU()(y)\n        y = self.conv2(y)\n        y = self.sigmoid(y)\n        \n        # Apply attention weights to input features\n        return x * y\n\nclass SkinToneModelWithLighting(nn.Module):\n    \"\"\"Convolutional Neural Network for skin tone classification with lighting awareness\"\"\"\n    def __init__(self, num_classes, dropout_rate=0.3):\n        super(SkinToneModelWithLighting, self).__init__()\n        \n        self.conv_block1 = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=3, padding=\"same\"),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2)\n        )\n        \n        self.conv_block2 = nn.Sequential(\n            nn.Conv2d(64, 128, kernel_size=3, padding=\"same\"),\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2)\n        )\n        \n        # Add first lighting attention after initial feature extraction\n        self.lighting_attention1 = LightingAwareAttention(128)\n        \n        self.conv_block3 = nn.Sequential(\n            nn.Conv2d(128, 256, kernel_size=3, padding=\"same\"),\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2)\n        )\n        \n        self.conv_block4 = nn.Sequential(\n            nn.Conv2d(256, 512, kernel_size=3, padding=\"same\"),\n            nn.BatchNorm2d(512),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2)\n        )\n        \n        # Add second lighting attention for higher-level features\n        self.lighting_attention2 = LightingAwareAttention(512)\n        \n        self.conv_block5 = nn.Sequential(\n            nn.Conv2d(512, 512, kernel_size=3, padding=\"same\"),\n            nn.BatchNorm2d(512),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2)\n        )\n        \n        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n        \n        # Dual branch for skin tone and lighting-aware features\n        self.skin_tone_branch = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(512, 256),\n            nn.ReLU(),\n            nn.Dropout(dropout_rate),\n        )\n        \n        self.lighting_branch = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(512, 128),\n            nn.ReLU(),\n            nn.Dropout(dropout_rate/2),\n        )\n        \n        # Combine both branches for final classification\n        self.classifier = nn.Linear(256 + 128, num_classes)\n        \n    def forward(self, x):\n        x = self.conv_block1(x)\n        x = self.conv_block2(x)\n        \n        # Apply first lighting attention\n        x = self.lighting_attention1(x)\n        \n        x = self.conv_block3(x)\n        x = self.conv_block4(x)\n        \n        # Apply second lighting attention\n        x = self.lighting_attention2(x)\n        \n        x = self.conv_block5(x)\n        x = self.global_avg_pool(x)\n        \n        # Split into two branches\n        skin_features = self.skin_tone_branch(x)\n        lighting_features = self.lighting_branch(x)\n        \n        # Concatenate features from both branches\n        combined_features = torch.cat((skin_features, lighting_features), dim=1)\n        \n        # Final classification\n        output = self.classifier(combined_features)\n        \n        return output\n\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n\ndataset = SkinToneDataset(image_paths, labels, transform=transform)\n\n# Split dataset into training and validation sets (80% train, 20% validation)\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\ntrain_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4,persistent_workers=True,pin_memory = True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4,persistent_workers=True,pin_memory = True)\n\nlighting_model = SkinToneModelWithLighting(num_classes=num_classes).to(device)\nprint(\"\\nLighting-Aware Model:\")\nprint(summary(lighting_model, input_size=(1, 3, 224, 224)))\ncriterion = nn.CrossEntropyLoss()\n    \noptimizer = torch.optim.Adam(lighting_model.parameters(), lr=0.0003)\n\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#FOR LIGHT ATTENTION\ndef train_one_epoch(lighting_model, dataloader, criterion, optimizer, device):\n    lighting_model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    for inputs, labels in dataloader:\n        inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)  # Move to GPU\n\n        optimizer.zero_grad()  \n\n        outputs = lighting_model(inputs)  \n        loss = criterion(outputs, labels)\n\n        loss.backward()  \n        optimizer.step() \n\n        running_loss += loss.item() * inputs.size(0)\n        _, predicted = outputs.max(1)\n        total += labels.size(0)\n        correct += predicted.eq(labels).sum().item()\n\n    epoch_loss = running_loss / len(dataloader.dataset)\n    epoch_acc = 100.0 * correct / total\n\n    return epoch_loss, epoch_acc\n\ndef validate(lighting_model, dataloader, criterion, device):\n    lighting_model.eval()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for inputs, labels in dataloader:\n            inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n\n            outputs = lighting_model(inputs)  # Forward pass\n            loss = criterion(outputs, labels)\n            running_loss += loss.item() * inputs.size(0)\n            _, predicted = outputs.max(1)\n            total += labels.size(0)\n            correct += predicted.eq(labels).sum().item()\n\n    epoch_loss = running_loss / len(dataloader.dataset)\n    epoch_acc = 100.0 * correct / total\n    print(epoch_loss)\n    print(epoch_acc)\n\n    return epoch_loss, epoch_acc\n\n\n# Ensure model is on GPU\nlighting_model.to(device)\n\n\nearly_stopping = EarlyStopping(patience=5, min_delta=0.001, save_path=\"best_skin_tone_model_with_lightingAttention.pth\")\n\ntrain1_losses = []\nval1_losses = []\ntrain1_accuracies = []\nval1_accuracies = []\nnum_epochs = 50\nfor epoch in range(num_epochs):\n    train_loss, train_acc = train_one_epoch(lighting_model, train_loader, criterion, optimizer, device)\n    val_loss, val_acc = validate(lighting_model, val_loader, criterion, device)\n\n     # Save loss and accuracy for visualization\n    train1_losses.append(train_loss)\n    val1_losses.append(val_loss)\n    train1_accuracies.append(train_acc)\n    val1_accuracies.append(val_acc)\n\n\n    print(f'Epoch {epoch+1}/{num_epochs}: '\n          f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, '\n          f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n\n    if early_stopping(val_loss, lighting_model):\n        print(f\"Training stopped early at epoch {epoch+1}\")\n        break\n\nprint(f'Training complete! Best validation loss: {early_stopping.best_loss:.4f}')\n\n# Load the best model for evaluation\nlighting_model.load_state_dict(torch.load(early_stopping.save_path, map_location=device))\nfinal_val_loss, final_val_acc = validate(lighting_model, val_loader, criterion, device)\nprint(f'Final model performance - Validation Loss: {final_val_loss:.4f}, Validation Accuracy: {final_val_acc:.2f}%')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"    # Plot Loss Curve\n    plt.figure(figsize=(10, 5))\n    plt.plot(train_losses, label=\"Train Loss\", marker=\"o\")\n    plt.plot(val_losses, label=\"Validation Loss\", marker=\"o\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Loss\")\n    plt.title(\"Loss Curve\")\n    plt.legend()\n    plt.grid()\n    plt.show()\n    \n    # Plot Accuracy Curve\n    plt.figure(figsize=(10, 5))\n    plt.plot(train_accuracies, label=\"Train Accuracy\", marker=\"o\")\n    plt.plot(val_accuracies, label=\"Validation Accuracy\", marker=\"o\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Accuracy (%)\")\n    plt.title(\"Accuracy Curve\")\n    plt.legend()\n    plt.grid()\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot Loss Curve\nplt.figure(figsize=(10, 5))\nplt.plot(train1_losses, label=\"Train Loss\", marker=\"o\")\nplt.plot(val1_losses, label=\"Validation Loss\", marker=\"o\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.title(\"Loss Curve\")\nplt.legend()\nplt.grid()\nplt.show()\n\n# Plot Accuracy Curve\nplt.figure(figsize=(10, 5))\nplt.plot(train1_accuracies, label=\"Train Accuracy\", marker=\"o\")\nplt.plot(val1_accuracies, label=\"Validation Accuracy\", marker=\"o\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy (%)\")\nplt.title(\"Accuracy Curve\")\nplt.legend()\nplt.grid()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Ensure all lists are the same length\nmin_epochs = min(len(train_losses), len(val_losses), len(train_accuracies), len(val_accuracies),\n                 len(train1_losses), len(val1_losses), len(train1_accuracies), len(val1_accuracies))\n\n# Trim lists to the shortest epoch count\ntrain_losses = train_losses[:min_epochs]\nval_losses = val_losses[:min_epochs]\ntrain_accuracies = train_accuracies[:min_epochs]\nval_accuracies = val_accuracies[:min_epochs]\ntrain1_losses = train1_losses[:min_epochs]\nval1_losses = val1_losses[:min_epochs]\ntrain1_accuracies = train1_accuracies[:min_epochs]\nval1_accuracies = val1_accuracies[:min_epochs]\n\n# Creating a dataframe for comparison\ndata = {\n    \"Epoch\": list(range(1, min_epochs + 1)),\n    \"Train Loss (Normal)\": train_losses,\n    \"Val Loss (Normal)\": val_losses,\n    \"Train Acc (Normal)\": train_accuracies,\n    \"Val Acc (Normal)\": val_accuracies,\n    \"Train Loss (Light Attention)\": train1_losses,\n    \"Val Loss (Light Attention)\": val1_losses,\n    \"Train Acc (Light Attention)\": train1_accuracies,\n    \"Val Acc (Light Attention)\": val1_accuracies,\n}\n\nresults_df = pd.DataFrame(data)\ndisplay(results_df)  # Display the table in Jupyter Notebook\n\n# Plot loss curves\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.plot(results_df[\"Epoch\"], results_df[\"Train Loss (Normal)\"], label='Train Loss (Normal)')\nplt.plot(results_df[\"Epoch\"], results_df[\"Val Loss (Normal)\"], label='Val Loss (Normal)')\nplt.plot(results_df[\"Epoch\"], results_df[\"Train Loss (Light Attention)\"], label='Train Loss (Light Attention)')\nplt.plot(results_df[\"Epoch\"], results_df[\"Val Loss (Light Attention)\"], label='Val Loss (Light Attention)')\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.title(\"Loss Comparison\")\nplt.legend()\nplt.grid()\n\n# Plot accuracy curves\nplt.subplot(1, 2, 2)\nplt.plot(results_df[\"Epoch\"], results_df[\"Train Acc (Normal)\"], label='Train Acc (Normal)')\nplt.plot(results_df[\"Epoch\"], results_df[\"Val Acc (Normal)\"], label='Val Acc (Normal)')\nplt.plot(results_df[\"Epoch\"], results_df[\"Train Acc (Light Attention)\"], label='Train Acc (Light Attention)')\nplt.plot(results_df[\"Epoch\"], results_df[\"Val Acc (Light Attention)\"], label='Val Acc (Light Attention)')\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy (%)\")\nplt.title(\"Accuracy Comparison\")\nplt.legend()\nplt.grid()\n\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
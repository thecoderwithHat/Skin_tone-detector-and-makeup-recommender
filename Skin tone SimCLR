{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11122792,"sourceType":"datasetVersion","datasetId":6936151},{"sourceId":12773567,"sourceType":"datasetVersion","datasetId":8075311}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # ================================\n# # 1. Imports\n# # ================================\n# import os\n# import torch\n# import torch.nn as nn\n# import torch.nn.functional as F\n# from torch.utils.data import Dataset, DataLoader\n# from torchvision import transforms\n# from PIL import Image\n# import numpy as np\n# from sklearn.cluster import KMeans\n# from torch import amp\n\n# # ================================\n# # 2. Explicitly collect all image paths\n# # ================================\n# base_img_dir = \"/kaggle/input/uktface/part1\"\n# valid_exts = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tiff\", \".webp\")\n\n# image_paths = []\n# for root, dirs, files in os.walk(base_img_dir):\n#     for file in files:\n#         if file.lower().endswith(valid_exts):\n#             image_paths.append(os.path.join(root, file))\n\n# print(f\"Found {len(image_paths)} images in {base_img_dir}\")\n\n# # ================================\n# # 3. Dataset Classes\n# # ================================\n# class SkinToneDataset(Dataset):\n#     def __init__(self, image_paths, transform=None):\n#         self.image_paths = image_paths\n#         self.transform = transform\n\n#     def __len__(self):\n#         return len(self.image_paths)\n\n#     def __getitem__(self, idx):\n#         img = Image.open(self.image_paths[idx]).convert(\"RGB\")\n#         if self.transform:\n#             img = self.transform(img)\n#         return img\n\n\n# class SimCLRDataset(Dataset):\n#     def __init__(self, image_paths, transform):\n#         self.image_paths = image_paths\n#         self.transform = transform\n\n#     def __len__(self):\n#         return len(self.image_paths)\n\n#     def __getitem__(self, idx):\n#         img = Image.open(self.image_paths[idx]).convert(\"RGB\")\n#         xi = self.transform(img)\n#         xj = self.transform(img)\n#         return xi, xj\n\n# # ================================\n# # 4. Feature Extractor (CNN backbone)\n# # ================================\n# class SkinToneFeatureExtractor(nn.Module):\n#     def __init__(self, dropout_rate=0.3):\n#         super(SkinToneFeatureExtractor, self).__init__()\n#         self.conv_block1 = nn.Sequential(\n#             nn.Conv2d(3, 64, kernel_size=3, padding=1),\n#             nn.BatchNorm2d(64), nn.ReLU(),\n#             nn.MaxPool2d(2)\n#         )\n#         self.conv_block2 = nn.Sequential(\n#             nn.Conv2d(64, 128, kernel_size=3, padding=1),\n#             nn.BatchNorm2d(128), nn.ReLU(),\n#             nn.MaxPool2d(2)\n#         )\n#         self.conv_block3 = nn.Sequential(\n#             nn.Conv2d(128, 256, kernel_size=3, padding=1),\n#             nn.BatchNorm2d(256), nn.ReLU(),\n#             nn.MaxPool2d(2),\n#             nn.Dropout2d(0.2)\n#         )\n#         self.conv_block4 = nn.Sequential(\n#             nn.Conv2d(256, 256, kernel_size=3, padding=1),\n#             nn.BatchNorm2d(256), nn.ReLU(),\n#             nn.MaxPool2d(2),\n#         )\n#         self.conv_block5 = nn.Sequential(\n#             nn.Conv2d(256, 512, kernel_size=3, padding=1),\n#             nn.BatchNorm2d(512), nn.ReLU(),\n#             nn.MaxPool2d(2)\n#         )\n#         self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n#         self.fc = nn.Sequential(\n#             nn.Flatten(),\n#             nn.Linear(512, 256),\n#             nn.ReLU(),\n#             nn.Dropout(dropout_rate)\n#         )\n\n#     def forward(self, x):\n#         x = self.conv_block1(x)\n#         x = self.conv_block2(x)\n#         x = self.conv_block3(x)\n#         x = self.conv_block4(x)\n#         x = self.conv_block5(x)\n#         x = self.global_avg_pool(x)\n#         x = self.fc(x)\n#         return x\n\n# # ================================\n# # 5. Projection Head\n# # ================================\n# class ProjectionHead(nn.Module):\n#     def __init__(self, in_dim=256, hidden_dim=256, out_dim=128):\n#         super(ProjectionHead, self).__init__()\n#         self.net = nn.Sequential(\n#             nn.Linear(in_dim, hidden_dim),\n#             nn.ReLU(),\n#             nn.Linear(hidden_dim, out_dim)\n#         )\n\n#     def forward(self, x):\n#         return self.net(x)\n\n# # ================================\n# # 6. Stable NT-Xent Loss (float16 safe)\n# # ================================\n# def nt_xent_loss(z_i, z_j, temperature=0.1):\n#     batch_size = z_i.shape[0]\n#     z = torch.cat([z_i, z_j], dim=0)\n#     z = F.normalize(z, dim=1)\n\n#     sim = torch.matmul(z, z.T) / temperature\n#     mask = torch.eye(2 * batch_size, dtype=torch.bool, device=z.device)\n#     sim_masked = sim.masked_fill(mask, -1e2)  # safe for float16\n\n#     labels = torch.arange(batch_size, device=z.device)\n#     labels = torch.cat([labels, labels], dim=0)\n#     loss = F.cross_entropy(sim_masked, labels)\n#     return loss\n\n# # ================================\n# # 7. Training SimCLR\n# # ================================\n# simclr_transform = transforms.Compose([\n#     transforms.RandomResizedCrop(size=224),\n#     transforms.RandomHorizontalFlip(),\n#     transforms.RandomApply([transforms.ColorJitter(0.8,0.8,0.8,0.2)], p=0.8),\n#     transforms.RandomGrayscale(p=0.2),\n#     transforms.GaussianBlur(kernel_size=9, sigma=(0.1,2.0)),\n#     transforms.ToTensor(),\n#     transforms.Normalize(mean=[0.485,0.456,0.406],\n#                          std=[0.229,0.224,0.225])\n# ])\n\n# train_dataset = SimCLRDataset(image_paths=image_paths, transform=simclr_transform)\n# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4,\n#                           pin_memory=True, persistent_workers=True)\n\n# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# encoder = nn.DataParallel(SkinToneFeatureExtractor()).to(device)\n# proj_head = nn.DataParallel(ProjectionHead(in_dim=256)).to(device)\n# optimizer = torch.optim.Adam(list(encoder.parameters()) + list(proj_head.parameters()), lr=1e-4)\n\n# scaler = amp.GradScaler()\n# accum_steps = 2  # gradient accumulation\n\n# epochs = 40\n# for epoch in range(epochs):\n#     encoder.train(); proj_head.train()\n#     total_loss = 0\n\n#     for batch_idx, (xi, xj) in enumerate(train_loader):\n#         xi, xj = xi.to(device), xj.to(device)\n#         with amp.autocast(device_type='cuda'):\n#             hi, hj = encoder(xi), encoder(xj)\n#             zi, zj = proj_head(hi), proj_head(hj)\n#             loss = nt_xent_loss(zi, zj) / accum_steps\n\n#         scaler.scale(loss).backward()\n\n#         if (batch_idx + 1) % accum_steps == 0:\n#             scaler.step(optimizer)\n#             scaler.update()\n#             optimizer.zero_grad()\n\n#         total_loss += loss.item() * xi.size(0) * accum_steps\n\n#         if (batch_idx + 1) % 50 == 0:\n#             print(f\"Epoch [{epoch+1}/{epochs}] | Batch [{batch_idx+1}/{len(train_loader)}] | \"\n#                   f\"Batch Loss: {loss.item()*accum_steps:.4f} | \"\n#                   f\"GPU Mem: {torch.cuda.memory_allocated()/1024**3:.2f} GB\")\n\n#         torch.cuda.empty_cache()\n\n#     avg_loss = total_loss / len(train_dataset)\n#     max_mem = torch.cuda.max_memory_allocated() / 1024**3\n#     print(f\"\\nEpoch [{epoch+1}/{epochs}] Summary:\")\n#     print(f\"Average Loss: {avg_loss:.4f}\")\n#     print(f\"GPU Memory Allocated: {torch.cuda.memory_allocated()/1024**3:.2f} GB\")\n#     print(f\"GPU Max Memory Allocated: {max_mem:.2f} GB\\n\")\n#     torch.cuda.reset_peak_memory_stats()\n\n# torch.save(encoder.module.state_dict(), \"simclr_encoder.pth\")\n# print(\"Pretrained encoder saved!\")\n\n# # ================================\n# # 8. Extract embeddings\n# # ================================\n# inference_transform = transforms.Compose([\n#     transforms.Resize((224,224)),\n#     transforms.ToTensor(),\n#     transforms.Normalize(mean=[0.485,0.456,0.406],\n#                          std=[0.229,0.224,0.225])\n# ])\n\n# dataset_infer = SkinToneDataset(image_paths=image_paths, transform=inference_transform)\n# loader_infer = DataLoader(dataset_infer, batch_size=32, shuffle=False, num_workers=4,\n#                           pin_memory=True, persistent_workers=True)\n\n# encoder = nn.DataParallel(SkinToneFeatureExtractor()).to(device)\n# encoder.load_state_dict(torch.load(\"simclr_encoder.pth\", map_location=device))\n# encoder.eval()\n\n# all_embeddings = []\n# with torch.no_grad():\n#     for imgs in loader_infer:\n#         imgs = imgs.to(device)\n#         feats = encoder(imgs)\n#         all_embeddings.append(feats.cpu().numpy())\n\n# all_embeddings = np.vstack(all_embeddings)\n# print(\"Extracted embeddings:\", all_embeddings.shape)\n\n# #k-means\n# k = 10\n# kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n# clusters = kmeans.fit_predict(all_embeddings)\n\n# print(\"Cluster assignments (first 20):\", clusters[:20])\n# print(\"Cluster counts:\", np.bincount(clusters))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T08:16:49.579901Z","iopub.execute_input":"2025-09-29T08:16:49.580744Z","iopub.status.idle":"2025-09-29T09:11:12.250664Z","shell.execute_reply.started":"2025-09-29T08:16:49.580702Z","shell.execute_reply":"2025-09-29T09:11:12.248411Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # ================================\n# # 1. Imports\n# # ================================\n# import os\n# import torch\n# import torch.nn as nn\n# import torch.nn.functional as F\n# from torch.utils.data import Dataset, DataLoader\n# from torchvision import transforms\n# from PIL import Image\n# import numpy as np\n# from sklearn.cluster import KMeans\n# from torch import amp\n\n# # ================================\n# # 2. Collect all image paths\n# # ================================\n# base_img_dir = \"/kaggle/input/uktface/part1\"\n# valid_exts = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tiff\", \".webp\")\n\n# image_paths = []\n# for root, dirs, files in os.walk(base_img_dir):\n#     for file in files:\n#         if file.lower().endswith(valid_exts):\n#             image_paths.append(os.path.join(root, file))\n\n# print(f\"Found {len(image_paths)} images in {base_img_dir}\")\n\n# # ================================\n# # 3. Dataset Classes\n# # ================================\n# class SkinToneDataset(Dataset):\n#     def __init__(self, image_paths, transform=None):\n#         self.image_paths = image_paths\n#         self.transform = transform\n\n#     def __len__(self):\n#         return len(self.image_paths)\n\n#     def __getitem__(self, idx):\n#         img = Image.open(self.image_paths[idx]).convert(\"RGB\")\n#         if self.transform:\n#             img = self.transform(img)\n#         return img\n\n\n# class SimCLRDataset(Dataset):\n#     def __init__(self, image_paths, transform):\n#         self.image_paths = image_paths\n#         self.transform = transform\n\n#     def __len__(self):\n#         return len(self.image_paths)\n\n#     def __getitem__(self, idx):\n#         img = Image.open(self.image_paths[idx]).convert(\"RGB\")\n#         xi = self.transform(img)\n#         xj = self.transform(img)\n#         return xi, xj\n\n# # ================================\n# # 4. Feature Extractor\n# # ================================\n# class SkinToneFeatureExtractor(nn.Module):\n#     def __init__(self, dropout_rate=0.3):\n#         super(SkinToneFeatureExtractor, self).__init__()\n#         self.conv_block1 = nn.Sequential(\n#             nn.Conv2d(3, 64, kernel_size=3, padding=1),\n#             nn.BatchNorm2d(64), nn.ReLU(),\n#             nn.MaxPool2d(2)\n#         )\n#         self.conv_block2 = nn.Sequential(\n#             nn.Conv2d(64, 128, kernel_size=3, padding=1),\n#             nn.BatchNorm2d(128), nn.ReLU(),\n#             nn.MaxPool2d(2)\n#         )\n#         self.conv_block3 = nn.Sequential(\n#             nn.Conv2d(128, 256, kernel_size=3, padding=1),\n#             nn.BatchNorm2d(256), nn.ReLU(),\n#             nn.MaxPool2d(2),\n#             nn.Dropout2d(0.2)\n#         )\n#         self.conv_block4 = nn.Sequential(\n#             nn.Conv2d(256, 256, kernel_size=3, padding=1),\n#             nn.BatchNorm2d(256), nn.ReLU(),\n#             nn.MaxPool2d(2),\n#         )\n#         self.conv_block5 = nn.Sequential(\n#             nn.Conv2d(256, 512, kernel_size=3, padding=1),\n#             nn.BatchNorm2d(512), nn.ReLU(),\n#             nn.MaxPool2d(2)\n#         )\n#         self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n#         self.fc = nn.Sequential(\n#             nn.Flatten(),\n#             nn.Linear(512, 256),\n#             nn.ReLU(),\n#             nn.Dropout(dropout_rate)\n#         )\n\n#     def forward(self, x):\n#         x = self.conv_block1(x)\n#         x = self.conv_block2(x)\n#         x = self.conv_block3(x)\n#         x = self.conv_block4(x)\n#         x = self.conv_block5(x)\n#         x = self.global_avg_pool(x)\n#         x = self.fc(x)\n#         return x\n\n# # ================================\n# # 5. Projection Head\n# # ================================\n# class ProjectionHead(nn.Module):\n#     def __init__(self, in_dim=256, hidden_dim=256, out_dim=128):\n#         super(ProjectionHead, self).__init__()\n#         self.net = nn.Sequential(\n#             nn.Linear(in_dim, hidden_dim),\n#             nn.ReLU(),\n#             nn.Linear(hidden_dim, out_dim)\n#         )\n\n#     def forward(self, x):\n#         return self.net(x)\n\n# # ================================\n# # 6. NT-Xent Loss (float16 safe)\n# # ================================\n# def nt_xent_loss(z_i, z_j, temperature=0.1):\n#     batch_size = z_i.shape[0]\n#     z = torch.cat([z_i, z_j], dim=0)\n#     z = F.normalize(z, dim=1)\n\n#     sim = torch.matmul(z, z.T) / temperature\n#     mask = torch.eye(2 * batch_size, dtype=torch.bool, device=z.device)\n#     sim_masked = sim.masked_fill(mask, -1e2)  # safe for float16\n\n#     labels = torch.arange(batch_size, device=z.device)\n#     labels = torch.cat([labels, labels], dim=0)\n#     loss = F.cross_entropy(sim_masked, labels)\n#     return loss\n\n# # ================================\n# # 7. SimCLR Training with Batch Size 128\n# # ================================\n# simclr_transform = transforms.Compose([\n#     transforms.RandomResizedCrop(size=224),\n#     transforms.RandomHorizontalFlip(),\n#     transforms.RandomApply([transforms.ColorJitter(0.8,0.8,0.8,0.2)], p=0.8),\n#     transforms.RandomGrayscale(p=0.2),\n#     transforms.GaussianBlur(kernel_size=9, sigma=(0.1,2.0)),\n#     transforms.ToTensor(),\n#     transforms.Normalize(mean=[0.485,0.456,0.406],\n#                          std=[0.229,0.224,0.225])\n# ])\n\n# train_dataset = SimCLRDataset(image_paths=image_paths, transform=simclr_transform)\n# train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True,\n#                           num_workers=4, pin_memory=True, persistent_workers=True)\n\n# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# encoder = nn.DataParallel(SkinToneFeatureExtractor()).to(device)\n# proj_head = nn.DataParallel(ProjectionHead(in_dim=256)).to(device)\n\n# optimizer = torch.optim.Adam(list(encoder.parameters()) + list(proj_head.parameters()), lr=1e-4)\n# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=40, eta_min=1e-6)\n\n# scaler = amp.GradScaler()\n# accum_steps = 2  # gradient accumulation for large batch\n\n# epochs = 40\n# for epoch in range(epochs):\n#     encoder.train(); proj_head.train()\n#     total_loss = 0\n\n#     for batch_idx, (xi, xj) in enumerate(train_loader):\n#         xi, xj = xi.to(device), xj.to(device)\n#         with amp.autocast(device_type='cuda'):\n#             hi, hj = encoder(xi), encoder(xj)\n#             zi, zj = proj_head(hi), proj_head(hj)\n#             loss = nt_xent_loss(zi, zj) / accum_steps\n\n#         scaler.scale(loss).backward()\n\n#         if (batch_idx + 1) % accum_steps == 0:\n#             scaler.step(optimizer)\n#             scaler.update()\n#             optimizer.zero_grad()\n#             scheduler.step()  # update LR per step\n\n#         total_loss += loss.item() * xi.size(0) * accum_steps\n\n#         if (batch_idx + 1) % 50 == 0:\n#             print(f\"Epoch [{epoch+1}/{epochs}] | Batch [{batch_idx+1}/{len(train_loader)}] | \"\n#                   f\"Batch Loss: {loss.item()*accum_steps:.4f} | \"\n#                   f\"GPU Mem: {torch.cuda.memory_allocated()/1024**3:.2f} GB | \"\n#                   f\"LR: {scheduler.get_last_lr()[0]:.6f}\")\n\n#         torch.cuda.empty_cache()\n\n#     avg_loss = total_loss / len(train_dataset)\n#     max_mem = torch.cuda.max_memory_allocated() / 1024**3\n#     print(f\"\\nEpoch [{epoch+1}/{epochs}] Summary:\")\n#     print(f\"Average Loss: {avg_loss:.4f}\")\n#     print(f\"GPU Memory Allocated: {torch.cuda.memory_allocated()/1024**3:.2f} GB\")\n#     print(f\"GPU Max Memory Allocated: {max_mem:.2f} GB\\n\")\n#     torch.cuda.reset_peak_memory_stats()\n\n# torch.save(encoder.module.state_dict(), \"simclr_encoder.pth\")\n# print(\"Pretrained encoder saved!\")\n\n# # ================================\n# # 8. Extract embeddings\n# # ================================\n# inference_transform = transforms.Compose([\n#     transforms.Resize((224,224)),\n#     transforms.ToTensor(),\n#     transforms.Normalize(mean=[0.485,0.456,0.406],\n#                          std=[0.229,0.224,0.225])\n# ])\n\n# dataset_infer = SkinToneDataset(image_paths=image_paths, transform=inference_transform)\n# loader_infer = DataLoader(dataset_infer, batch_size=128, shuffle=False,\n#                           num_workers=4, pin_memory=True, persistent_workers=True)\n\n# encoder = nn.DataParallel(SkinToneFeatureExtractor()).to(device)\n# encoder.load_state_dict(torch.load(\"simclr_encoder.pth\", map_location=device))\n# encoder.eval()\n\n# all_embeddings = []\n# with torch.no_grad():\n#     for imgs in loader_infer:\n#         imgs = imgs.to(device)\n#         feats = encoder(imgs)\n#         all_embeddings.append(feats.cpu().numpy())\n\n# all_embeddings = np.vstack(all_embeddings)\n# print(\"Extracted embeddings:\", all_embeddings.shape)\n\n# # ================================\n# # 9. KMeans Clustering\n# # ================================\n# k = 10\n# kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n# clusters = kmeans.fit_predict(all_embeddings)\n\n# print(\"Cluster assignments (first 20):\", clusters[:20])\n# print(\"Cluster counts:\", np.bincount(clusters))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T09:13:58.257909Z","iopub.execute_input":"2025-09-29T09:13:58.258669Z","iopub.status.idle":"2025-09-29T09:38:45.157382Z","shell.execute_reply.started":"2025-09-29T09:13:58.258641Z","shell.execute_reply":"2025-09-29T09:38:45.155994Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ================================\n# 1. Imports\n# ================================\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom PIL import Image\nimport numpy as np\nfrom sklearn.cluster import KMeans\nfrom torch import amp\nfrom sklearn.metrics import silhouette_score\nfrom sklearn.manifold import TSNE\nimport matplotlib.pyplot as plt\n# ================================\n# 2. Collect all image paths\n# ================================\nbase_img_dir = \"/kaggle/input/uktface/part1\"\nvalid_exts = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tiff\", \".webp\")\n\nimage_paths = []\nfor root, dirs, files in os.walk(base_img_dir):\n    for file in files:\n        if file.lower().endswith(valid_exts):\n            image_paths.append(os.path.join(root, file))\n\nprint(f\"Found {len(image_paths)} images in {base_img_dir}\")\n\n# ================================\n# 3. Dataset Classes\n# ================================\nclass SkinToneDataset(Dataset):\n    def __init__(self, image_paths, transform=None):\n        self.image_paths = image_paths\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        img = Image.open(self.image_paths[idx]).convert(\"RGB\")\n        if self.transform:\n            img = self.transform(img)\n        return img\n\n\nclass SimCLRDataset(Dataset):\n    def __init__(self, image_paths, transform):\n        self.image_paths = image_paths\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        img = Image.open(self.image_paths[idx]).convert(\"RGB\")\n        xi = self.transform(img)\n        xj = self.transform(img)\n        return xi, xj\n\n# ================================\n# 4. Feature Extractor\n# ================================\nclass SkinToneFeatureExtractor(nn.Module):\n    def __init__(self, dropout_rate=0.3):\n        super(SkinToneFeatureExtractor, self).__init__()\n        self.conv_block1 = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n            nn.BatchNorm2d(64), nn.ReLU(),\n            nn.MaxPool2d(2)\n        )\n        self.conv_block2 = nn.Sequential(\n            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n            nn.BatchNorm2d(128), nn.ReLU(),\n            nn.MaxPool2d(2)\n        )\n        self.conv_block3 = nn.Sequential(\n            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n            nn.BatchNorm2d(256), nn.ReLU(),\n            nn.MaxPool2d(2),\n            nn.Dropout2d(0.2)\n        )\n        self.conv_block4 = nn.Sequential(\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.BatchNorm2d(256), nn.ReLU(),\n            nn.MaxPool2d(2),\n        )\n        self.conv_block5 = nn.Sequential(\n            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n            nn.BatchNorm2d(512), nn.ReLU(),\n            nn.MaxPool2d(2)\n        )\n        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(512, 256),\n            nn.ReLU(),\n            nn.Dropout(dropout_rate)\n        )\n\n    def forward(self, x):\n        x = self.conv_block1(x)\n        x = self.conv_block2(x)\n        x = self.conv_block3(x)\n        x = self.conv_block4(x)\n        x = self.conv_block5(x)\n        x = self.global_avg_pool(x)\n        x = self.fc(x)\n        return x\n\n# ================================\n# 5. Projection Head\n# ================================\nclass ProjectionHead(nn.Module):\n    def __init__(self, in_dim=256, hidden_dim=256, out_dim=128):\n        super(ProjectionHead, self).__init__()\n        self.net = nn.Sequential(\n            nn.Linear(in_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, out_dim)\n        )\n\n    def forward(self, x):\n        return self.net(x)\n\n# ================================\n# 6. NT-Xent Loss (float16 safe)\n# ================================\ndef nt_xent_loss(z_i, z_j, temperature=0.1):\n    batch_size = z_i.shape[0]\n    z = torch.cat([z_i, z_j], dim=0)\n    z = F.normalize(z, dim=1)\n\n    sim = torch.matmul(z, z.T) / temperature\n    mask = torch.eye(2 * batch_size, dtype=torch.bool, device=z.device)\n    sim_masked = sim.masked_fill(mask, -1e2)  # safe for float16\n\n    labels = torch.arange(batch_size, device=z.device)\n    labels = torch.cat([labels, labels], dim=0)\n    loss = F.cross_entropy(sim_masked, labels)\n    return loss\n\n# ================================\n# 7. SimCLR Training with Batch Size 128 & LR=0.001\n# ================================\nsimclr_transform = transforms.Compose([\n    transforms.RandomResizedCrop(size=224),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomApply([transforms.ColorJitter(0.8,0.8,0.8,0.2)], p=0.8),\n    transforms.RandomGrayscale(p=0.2),\n    transforms.GaussianBlur(kernel_size=9, sigma=(0.1,2.0)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485,0.456,0.406],\n                         std=[0.229,0.224,0.225])\n])\n\ntrain_dataset = SimCLRDataset(image_paths=image_paths, transform=simclr_transform)\ntrain_loader = DataLoader(train_dataset, batch_size=128, shuffle=True,\n                          num_workers=4, pin_memory=True, persistent_workers=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nencoder = nn.DataParallel(SkinToneFeatureExtractor()).to(device)\nproj_head = nn.DataParallel(ProjectionHead(in_dim=256)).to(device)\n\noptimizer = torch.optim.Adam(list(encoder.parameters()) + list(proj_head.parameters()), lr=1e-3)  # LR = 0.001\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=40, eta_min=1e-6)\n\nscaler = amp.GradScaler()\naccum_steps = 2  # gradient accumulation\n\nepochs = 70\nfor epoch in range(epochs):\n    encoder.train(); proj_head.train()\n    total_loss = 0\n\n    for batch_idx, (xi, xj) in enumerate(train_loader):\n        xi, xj = xi.to(device), xj.to(device)\n        with amp.autocast(device_type='cuda'):\n            hi, hj = encoder(xi), encoder(xj)\n            zi, zj = proj_head(hi), proj_head(hj)\n            loss = nt_xent_loss(zi, zj) / accum_steps\n\n        scaler.scale(loss).backward()\n\n        if (batch_idx + 1) % accum_steps == 0:\n            scaler.step(optimizer)\n            scaler.update()\n            optimizer.zero_grad()\n            scheduler.step()  # update LR per step\n\n        total_loss += loss.item() * xi.size(0) * accum_steps\n\n        if (batch_idx + 1) % 50 == 0:\n            print(f\"Epoch [{epoch+1}/{epochs}] | Batch [{batch_idx+1}/{len(train_loader)}] | \"\n                  f\"Batch Loss: {loss.item()*accum_steps:.4f} | \"\n                  f\"GPU Mem: {torch.cuda.memory_allocated()/1024**3:.2f} GB | \"\n                  f\"LR: {scheduler.get_last_lr()[0]:.6f}\")\n\n        torch.cuda.empty_cache()\n\n    avg_loss = total_loss / len(train_dataset)\n    max_mem = torch.cuda.max_memory_allocated() / 1024**3\n    print(f\"\\nEpoch [{epoch+1}/{epochs}] Summary:\")\n    print(f\"Average Loss: {avg_loss:.4f}\")\n    print(f\"GPU Memory Allocated: {torch.cuda.memory_allocated()/1024**3:.2f} GB\")\n    print(f\"GPU Max Memory Allocated: {max_mem:.2f} GB\\n\")\n    torch.cuda.reset_peak_memory_stats()\n\ntorch.save(encoder.module.state_dict(), \"simclr_encoder.pth\")\nprint(\"Pretrained encoder saved!\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T09:38:47.427388Z","iopub.execute_input":"2025-09-29T09:38:47.428381Z","iopub.status.idle":"2025-09-29T09:54:08.410034Z","shell.execute_reply.started":"2025-09-29T09:38:47.428346Z","shell.execute_reply":"2025-09-29T09:54:08.408912Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ================================\n# 8. Extract embeddings\n# ================================\ninference_transform = transforms.Compose([\n    transforms.Resize((224,224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485,0.456,0.406],\n                         std=[0.229,0.224,0.225])\n])\n\ndataset_infer = SkinToneDataset(image_paths=image_paths, transform=inference_transform)\nloader_infer = DataLoader(dataset_infer, batch_size=128, shuffle=False,\n                          num_workers=4, pin_memory=True, persistent_workers=True)\n\n# âœ… Load model WITHOUT DataParallel (because we saved encoder.module.state_dict)\nencoder = SkinToneFeatureExtractor().to(device)\nencoder.load_state_dict(torch.load(\"simclr_encoder.pth\", map_location=device))\nencoder.eval()\n\nall_embeddings = []\nwith torch.no_grad():\n    for imgs in loader_infer:\n        imgs = imgs.to(device)\n        feats = encoder(imgs)\n        all_embeddings.append(feats.cpu().numpy())\n\nall_embeddings = np.vstack(all_embeddings)\nprint(\"Extracted embeddings:\", all_embeddings.shape)\n\n# ================================\n# 9. KMeans Clustering\n# ================================\nk = 10\nkmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\nclusters = kmeans.fit_predict(all_embeddings)\n\nprint(\"Cluster assignments (first 20):\", clusters[:20])\nprint(\"Cluster counts:\", np.bincount(clusters))\n\n# ================================\n# 10. Optional: Visualize clusters in 2D with t-SNE\n# ================================\ntsne = TSNE(n_components=2, random_state=42, perplexity=30)\nembeddings_2d = tsne.fit_transform(all_embeddings)\n\nplt.figure(figsize=(10, 8))\nscatter = plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1],\n                      c=clusters, cmap=\"tab10\", s=15)\nplt.legend(*scatter.legend_elements(), title=\"Clusters\")\nplt.title(\"t-SNE visualization of SkinTone embeddings\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}